{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] OnePlus Bullets Wireless Z2\n",
      "[1] MacBook Air Microphone\n"
     ]
    }
   ],
   "source": [
    "from pvrecorder import PvRecorder\n",
    "\n",
    "for index, device in enumerate(PvRecorder.get_available_devices()):\n",
    "    print(f\"[{index}] {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import io\n",
    "import wave\n",
    "import IPython\n",
    "import pyaudio\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import speech_recognition as sr\n",
    "\n",
    "from settings import OPENAI_API_KEY\n",
    "\n",
    "\n",
    "def byte_stream_generator(response, buffer_size=256):\n",
    "    \"\"\"\n",
    "    Generator function that yields a stream of bytes from the response.\n",
    "\n",
    "    :param response: The response object from the OpenAI API call.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        for byte_chunk in response.iter_bytes(chunk_size=buffer_size):\n",
    "            if byte_chunk:  # Only yield non-empty byte chunks\n",
    "                yield byte_chunk\n",
    "            else:\n",
    "                print(\"Skipped an empty or corrupted packet\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error while streaming bytes: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "class SpeechBot:\n",
    "    def __init__(\n",
    "            self, \n",
    "            audio_handling_prompt,\n",
    "            tp_model_name='gpt-4',\n",
    "            stt_model_name='whisper-1',\n",
    "            tts_model_name='tts-1',\n",
    "            tts_voice='alloy',\n",
    "            pause_threshold=2\n",
    "        ):\n",
    "        self.recognizer = sr.Recognizer()\n",
    "        self.pause_threshold = pause_threshold\n",
    "        self.client = OpenAI(\n",
    "            api_key=OPENAI_API_KEY,\n",
    "        )\n",
    "\n",
    "        self.audio_handling_prompt = audio_handling_prompt\n",
    "        self.stt_model_name = stt_model_name\n",
    "        self.tp_model_name = tp_model_name\n",
    "        self.tts_model_name = tts_model_name\n",
    "        self.tts_voice = tts_voice\n",
    "\n",
    "        self.messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": audio_handling_prompt\n",
    "            }\n",
    "        ]\n",
    "    \n",
    "    def listen(self):\n",
    "        \"\"\"Capture audio from the microphone until the user stops speaking and return as text.\"\"\"\n",
    "\n",
    "        with sr.Microphone() as source:\n",
    "            print(\"Listening...\")\n",
    "            self.recognizer.adjust_for_ambient_noise(source)\n",
    "            self.recognizer.pause_threshold = self.pause_threshold\n",
    "            \n",
    "            # Listen continuously until the user stops speaking\n",
    "            audio = self.recognizer.listen(source)\n",
    "            audio_file_path = 'data/audio.wav'\n",
    "            with open(audio_file_path, 'wb') as f:\n",
    "                f.write(audio.get_wav_data())\n",
    "\n",
    "        try:\n",
    "            print(\"Recognizing...\")\n",
    "            # response = self.client.audio.transcriptions.with_streaming_response.create(\n",
    "            #     file=open(audio_file_path, 'rb'),\n",
    "            #     model=self.stt_model_name\n",
    "            # )\n",
    "\n",
    "            response = self.recognizer.recognize_google_cloud(audio, language='en-in')\n",
    "            print(response)\n",
    "            text = response.text.strip()\n",
    "\n",
    "            self.messages.append({\n",
    "                \"role\": \"user\",\n",
    "                \"content\": text\n",
    "            })\n",
    "\n",
    "            os.remove(audio_file_path)\n",
    "            \n",
    "            print(f\"You said: {text}\")\n",
    "            return text\n",
    "        except sr.UnknownValueError as e:\n",
    "            print(\"Sorry, I did not understand that.\")\n",
    "            raise e\n",
    "        except sr.RequestError as e:\n",
    "            print(\"Sorry, there seems to be a problem with the service.\")\n",
    "            raise e\n",
    "    \n",
    "    def process_text(self):\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.tp_model_name,\n",
    "            messages=self.messages,\n",
    "            stream=True\n",
    "        )\n",
    "        # create variables to collect the stream of chunks\n",
    "        collected_chunks = []\n",
    "        collected_messages = []\n",
    "        # iterate through the stream of events\n",
    "        for chunk in response:\n",
    "            collected_chunks.append(chunk)  # save the event response\n",
    "            chunk_message = chunk.choices[0].delta.content  # extract the message\n",
    "            collected_messages.append(chunk_message)  # save the message\n",
    "            print(chunk_message, end=\"\")  # print the message\n",
    "            \n",
    "        collected_messages = [m for m in collected_messages if m is not None]\n",
    "        full_reply_content = ''.join(collected_messages)\n",
    "\n",
    "        self.messages.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": full_reply_content\n",
    "        })\n",
    "        return full_reply_content\n",
    "    \n",
    "    \n",
    "    def speak(self, text):\n",
    "        speech_file_path = 'data/speech.mp3'\n",
    "        with self.client.audio.speech.with_streaming_response.create(\n",
    "            model=\"tts-1-hd\",\n",
    "            voice=\"nova\",\n",
    "            input=text,\n",
    "            response_format= \"wav\",\n",
    "        ) as response:\n",
    "            try:\n",
    "                # Initialize PyAudio\n",
    "                p = pyaudio.PyAudio()\n",
    "\n",
    "                # Open the stream\n",
    "                stream = p.open(\n",
    "                    format=pyaudio.paInt16, \n",
    "                    channels=1, \n",
    "                    rate=16000, \n",
    "                    output=True\n",
    "                )\n",
    "\n",
    "                # Initialize the WAV header\n",
    "                wav_header = None\n",
    "\n",
    "                for audio_chunk in byte_stream_generator(response=response):\n",
    "                    # Check if this is the first chunk (WAV header)\n",
    "                    if wav_header is None:\n",
    "                        wav_header = audio_chunk\n",
    "                        # Extract the WAV format parameters from the header\n",
    "                        wav_format = wave.open(io.BytesIO(wav_header), 'rb')\n",
    "                        channels, samp_width, framerate, nframes, comptype, compname = wav_format.getparams()\n",
    "                        # Reopen the stream with the correct parameters\n",
    "                        stream = p.open(\n",
    "                            format=p.get_format_from_width(samp_width), \n",
    "                            channels=channels, \n",
    "                            rate=framerate, \n",
    "                            output=True\n",
    "                        )\n",
    "                    else:\n",
    "                        # Write the audio chunk to the stream\n",
    "                        stream.write(audio_chunk)\n",
    "\n",
    "                # Close the stream and PyAudio\n",
    "                stream.stop_stream()\n",
    "                stream.close()\n",
    "                p.terminate()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error during playback: {e}\")\n",
    "        \n",
    "        # IPython.display.Audio(speech_file_path)\n",
    "        # os.remove(speech_file_path)\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            text = self.listen()\n",
    "            if not text:\n",
    "                continue\n",
    "            response = self.process_text()\n",
    "            \n",
    "            self.speak(response)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_HANDLING_PROMPT = \\\n",
    "\"\"\"\n",
    "You are a hiring recruiter lead at a tech saas company. You are simulating the recruiter talking to a sales agent from a company \"foundit\", and \n",
    "responding to the sales agent's offer to sell you a recruiting solution. You need to dig deeper into value proposition,\n",
    "lay objections on the product and decide if you want to take a demo or not based on the sales agents conversations.\n",
    "You also need to bring up issues on the recent bad PR the company faced about its poor pricing. \n",
    "Tone of conversation - rude, blunt and a little fast paced.\n",
    "\"\"\"\n",
    "\n",
    "sales_agent = SpeechBot(AUDIO_HANDLING_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "Recognizing...\n",
      "Transcription(text='What are you selling today?')\n",
      "You said: What are you selling today?\n",
      "Assistant: Hello! Today, we're introducing a revolutionary new service that uses cutting-edge machine learning algorithms to greatly improve your company's hiring process. This service provides highly accurate job recommendations, narrowing down the pool of candidates to ones that are the best match for your specific needs. \n",
      "\n",
      "Before we go further, could you please share the major challenges your company currently faces when trying to hire new employees? It'll help us understand your needs better and demonstrate how our new service can solve these issues for you.\n"
     ]
    }
   ],
   "source": [
    "sales_agent.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
